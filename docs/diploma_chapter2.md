
---

# ГЛАВА 2. РАЗРАБОТКА МОДЕЛИ МАШИННОГО ОБУЧЕНИЯ

## 2.1 Формирование обучающего датасета

Качество модели машинного обучения непосредственно зависит от характеристик обучающей выборки. Для данного исследования использовалась комбинация открытого датасета и собственной выборки казахстанских URL-адресов.

**Основной датасет.** В качестве базовой обучающей выборки использован открытый датасет Phishing-Dataset, опубликованный исследователем Грегой Врбанчичем на платформе GitHub. Датасет содержит 58 645 записей с равномерным распределением классов: 50% легитимных и 50% фишинговых URL-адресов. Каждая запись характеризуется 111 числовыми признаками, извлечёнными из структуры URL-адреса.

Выбор данного датасета обусловлен рядом преимуществ: значительный объём выборки, сбалансированность классов, воспроизводимость результатов и возможность сравнения с опубликованными исследованиями других авторов.

**Казахстанский датасет.** Для адаптации модели к национальной специфике была сформирована дополнительная выборка, включающая 988 URL-адресов казахстанских веб-ресурсов. В категорию легитимных вошли официальные сайты банковских учреждений (kaspi.kz, halykbank.kz, fortebank.com), государственных сервисов (egov.kz, elicense.kz), телекоммуникационных операторов (beeline.kz, kcell.kz), крупных интернет-магазинов и новостных порталов.

Фишинговые URL-адреса казахстанской выборки представляют собой синтетически сгенерированные примеры, моделирующие типичные паттерны атак: typosquatting известных брендов (kaspii.kz, kasp1.kz), использование подозрительных доменов верхнего уровня (kaspi-secure.xyz), длинные URL-адреса с множественными поддоменами.

**Объединённый датасет** включает 59 633 записи и обеспечивает репрезентативность как глобальных угроз, так и специфических для казахстанского сегмента интернета.

## 2.2 Извлечение и анализ признаков

Процесс извлечения признаков (feature extraction) является критически важным этапом, определяющим информативность входных данных для модели. В рамках исследования реализован модуль извлечения 111 признаков из URL-адреса, систематизированных по следующим категориям.

**Структурные признаки (27 признаков):**
- Общая длина URL-адреса
- Длина доменного имени
- Количество поддоменов
- Глубина пути (количество сегментов после домена)
- Длина строки запроса (query string)
- Наличие и количество параметров

**Лексические признаки (34 признака):**
- Количество цифр в различных частях URL
- Количество специальных символов (точки, дефисы, подчёркивания)
- Наличие IP-адреса вместо доменного имени
- Присутствие подозрительных ключевых слов (login, verify, secure, update, account, confirm)
- Использование сокращённых URL-сервисов (bit.ly, tinyurl.com)

**Доменные признаки (25 признаков):**
- Домен верхнего уровня (TLD)
- Возраст домена (при доступности WHOIS)
- Соответствие домена известным брендам
- Наличие typosquatting (расстояние Левенштейна до известных брендов)

**Признаки безопасности (15 признаков):**
- Использование протокола HTTPS
- Наличие нестандартного порта
- Присутствие символа @ в URL
- Использование шестнадцатеричного кодирования

**Статистические признаки (10 признаков):**
- Энтропия URL-адреса
- Соотношение букв и цифр
- Максимальная длина токена

Проведённый корреляционный анализ выявил признаки с наибольшей предсказательной силой. Коэффициент корреляции Пирсона с целевой переменной составил: длина URL (0.42), количество точек (0.38), наличие HTTPS (-0.35), количество цифр в домене (0.31).

## 2.3 Предобработка данных

Подготовка данных для обучения модели включала несколько последовательных этапов.

**Обработка пропущенных значений.** Анализ датасета выявил отсутствие пропущенных значений, что исключило необходимость применения методов импутации.

**Масштабирование признаков.** Для нормализации числовых признаков применён метод стандартизации (StandardScaler), преобразующий распределение каждого признака к нулевому среднему и единичной дисперсии. Данное преобразование критически важно для алгоритмов, чувствительных к масштабу признаков, и обеспечивает стабильность обучения градиентного бустинга.

**Разделение выборки.** Датасет разделён на обучающую (80%) и тестовую (20%) выборки с использованием стратифицированного разбиения для сохранения пропорций классов. Размер обучающей выборки составил 47 706 записей, тестовой — 11 927 записей.

## 2.4 Обучение и настройка модели XGBoost

Для решения задачи классификации выбран алгоритм XGBoost (eXtreme Gradient Boosting), представляющий собой оптимизированную реализацию градиентного бустинга над деревьями решений.

**Обоснование выбора алгоритма.** XGBoost демонстрирует ряд преимуществ для задачи обнаружения фишинга:
- Высокая точность на задачах табличной классификации
- Встроенная регуляризация L1 и L2, предотвращающая переобучение
- Эффективная обработка разреженных данных
- Параллельное построение деревьев, обеспечивающее высокую скорость обучения
- Возможность извлечения важности признаков для интерпретации модели

**Гиперпараметры модели.** По результатам экспериментов установлены следующие значения гиперпараметров:
- n_estimators = 100 (количество деревьев в ансамбле)
- max_depth = 6 (максимальная глубина дерева)
- learning_rate = 0.1 (скорость обучения)
- subsample = 0.8 (доля объектов для построения каждого дерева)
- colsample_bytree = 0.8 (доля признаков для построения каждого дерева)

Выбор параметров осуществлён с учётом баланса между точностью модели и риском переобучения. Умеренная глубина деревьев (6) и использование подвыборки объектов и признаков обеспечивают регуляризирующий эффект.

## 2.5 Оценка качества модели

Оценка эффективности обученной модели проведена на тестовой выборке с использованием стандартных метрик бинарной классификации.

**Матрица ошибок** фиксирует распределение предсказаний модели:
- Истинно положительные (TP): 5 674 — корректно идентифицированные фишинговые URL
- Истинно отрицательные (TN): 5 598 — корректно идентифицированные легитимные URL  
- Ложно положительные (FP): 341 — легитимные URL, ошибочно классифицированные как фишинг
- Ложно отрицательные (FN): 314 — пропущенные фишинговые URL

**Основные метрики качества:**

| Метрика | Значение |
|---------|----------|
| Accuracy (Точность) | 94.5% |
| Precision (Точность положительного класса) | 94.4% |
| Recall (Полнота) | 95.1% |
| F1 Score (Гармоническое среднее) | 94.8% |
| AUC-ROC | 0.98 |

**Интерпретация результатов.** Достигнутые показатели свидетельствуют о высокой эффективности модели. Значение Recall 95.1% означает, что модель обнаруживает подавляющее большинство фишинговых URL-адресов, пропуская лишь около 5%. Precision 94.4% указывает на низкий уровень ложных срабатываний, что критически важно для пользовательского опыта.

**Кросс-валидация.** Для проверки устойчивости результатов проведена 5-кратная стратифицированная кросс-валидация. Среднее значение F1 Score составило 94.6% со стандартным отклонением 0.8%, что подтверждает стабильность модели на различных подвыборках данных.

## 2.6 Сравнительный анализ алгоритмов

Для обоснования выбора XGBoost проведено сравнение с альтернативными алгоритмами машинного обучения.

| Алгоритм | Accuracy | F1 Score | AUC-ROC | Время обучения |
|----------|----------|----------|---------|----------------|
| Logistic Regression | 91.2% | 91.5% | 0.95 | 2.1 сек |
| Random Forest | 93.8% | 94.1% | 0.97 | 15.3 сек |
| **XGBoost** | **94.5%** | **94.8%** | **0.98** | 8.7 сек |

Результаты подтверждают превосходство XGBoost по всем ключевым метрикам при умеренном времени обучения.

## 2.7 Анализ важности признаков

Интерпретируемость модели обеспечивается анализом важности признаков, вычисляемой на основе частоты использования признаков в деревьях решений и величины улучшения качества расщепления.

**Топ-10 наиболее важных признаков:**

1. Общая длина URL-адреса (0.087)
2. Количество точек в URL (0.072)
3. Длина доменного имени (0.065)
4. Наличие протокола HTTPS (0.058)
5. Количество поддоменов (0.054)
6. Количество цифр в домене (0.048)
7. Наличие символа @ (0.043)
8. Длина строки запроса (0.039)
9. Количество дефисов (0.036)
10. Typosquatting score (0.033)

Полученные результаты согласуются с теоретическими представлениями о характерных признаках фишинговых URL-адресов и подтверждают корректность подхода к извлечению признаков.

## 2.8 Выводы по второй главе

По результатам разработки модели машинного обучения сформулированы следующие выводы:

1. Сформирован объединённый датасет из 59 633 URL-адресов, включающий казахстанские веб-ресурсы для адаптации к национальной специфике.

2. Реализован модуль извлечения 111 признаков, охватывающих структурные, лексические, доменные и статистические характеристики URL-адресов.

3. Обучена модель XGBoost, достигающая точности 94.5% и F1 Score 94.8% на тестовой выборке.

4. Сравнительный анализ подтвердил превосходство XGBoost над альтернативными алгоритмами.

5. Анализ важности признаков обеспечивает интерпретируемость решений модели и согласуется с экспертными знаниями о характеристиках фишинговых URL.
